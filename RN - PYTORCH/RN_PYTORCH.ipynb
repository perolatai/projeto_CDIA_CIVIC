{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "\n",
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "from torch.optim import Adam\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação dos dados\n",
    "\n",
    "civic = pd.read_csv(r'civic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = civic[['evidence_type']]\n",
    "\n",
    "X = civic.drop(['entrez_id', 'evidence_type', 'gene_id', 'evidence_level', 'citation_id', 'source_type', 'citation', 'evidence_id', 'representative_transcript',\n",
    "                    'ensembl_version', 'allele_registry_id'], axis=1).apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence_type\n",
       "Predictive       62.873563\n",
       "Predisposing     16.513410\n",
       "Prognostic       13.103448\n",
       "Diagnostic        4.980843\n",
       "Oncogenic         1.724138\n",
       "Functional        0.804598\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Variaveis de treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)\n",
    "\n",
    "(y_train.value_counts()/y_train.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence_type\n",
       "Predictive       1641\n",
       "Predisposing      431\n",
       "Prognostic        342\n",
       "Diagnostic        130\n",
       "Oncogenic          45\n",
       "Functional         21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence_type\n",
       "Predictive       62.937063\n",
       "Predisposing     16.472416\n",
       "Prognostic       13.131313\n",
       "Diagnostic        4.972805\n",
       "Oncogenic         1.709402\n",
       "Functional        0.777001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.value_counts()/y_test.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evidence_type\n",
       "Prognostic       21\n",
       "Predisposing     21\n",
       "Predictive       21\n",
       "Oncogenic        21\n",
       "Functional       21\n",
       "Diagnostic       21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Balanceando os dados\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando as colunas em números\n",
    "\n",
    "labels = {'Predictive':0, 'Predisposing':1, 'Prognostic':2, 'Diagnostic':3, 'Oncogenic':4, 'Functional':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b05312f5fdc4>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['evidence_type_num'] = y['evidence_type']\n",
      "C:\\Users\\letic\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#Cria a coluna evidence_type \n",
    "\n",
    "y['evidence_type_num'] = y['evidence_type']\n",
    "\n",
    "#Convertendos os valores em números\n",
    "\n",
    "y.evidence_type_num = [labels[item] for item in y.evidence_type_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values are: \n",
      "   entrez_id variant                         disease    doid phenotypes drugs  \\\n",
      "0       3717   V617F               Lymphoid Leukemia  1037.0        NaN   NaN   \n",
      "1       5156   D842V  Gastrointestinal Stromal Tumor  9253.0        NaN   NaN   \n",
      "2       1788    R882          Acute Myeloid Leukemia  9119.0        NaN   NaN   \n",
      "3       1788    R882          Acute Myeloid Leukemia  9119.0        NaN   NaN   \n",
      "4       3717   V617F        Chronic Myeloid Leukemia  8552.0        NaN   NaN   \n",
      "\n",
      "  drug_interaction_type evidence_type evidence_direction evidence_level  ...  \\\n",
      "0                   NaN    Diagnostic           Supports              B  ...   \n",
      "1                   NaN    Diagnostic           Supports              B  ...   \n",
      "2                   NaN    Diagnostic           Supports              B  ...   \n",
      "3                   NaN    Diagnostic           Supports              B  ...   \n",
      "4                   NaN    Diagnostic           Supports              B  ...   \n",
      "\n",
      "  ensembl_version reference_build  \\\n",
      "0            75.0          GRCh37   \n",
      "1            75.0          GRCh37   \n",
      "2            75.0          GRCh37   \n",
      "3            75.0          GRCh37   \n",
      "4            75.0          GRCh37   \n",
      "\n",
      "                                     variant_summary variant_origin  \\\n",
      "0  JAK2 V617F is a highly recurrent mutation in m...        Somatic   \n",
      "1  PDGFRA D842 mutations are characterized broadl...        Somatic   \n",
      "2  DNMT3A R882 mutations are associated with cyto...        Somatic   \n",
      "3  DNMT3A R882 mutations are associated with cyto...        Somatic   \n",
      "4  JAK2 V617F is a highly recurrent mutation in m...        Somatic   \n",
      "\n",
      "  is_flagged                              variant_types  \\\n",
      "0      False  missense_variant,gain_of_function_variant   \n",
      "1      False                           missense_variant   \n",
      "2      False                           missense_variant   \n",
      "3      False                           missense_variant   \n",
      "4      False  missense_variant,gain_of_function_variant   \n",
      "\n",
      "                                    hgvs_expressions  \\\n",
      "0  NC_000009.11:g.5073770G>T,NM_004972.3:c.1849G>...   \n",
      "1  NM_006206.4:c.2525A>T,NP_006197.1:p.Asp842Val,...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4  NC_000009.11:g.5073770G>T,NM_004972.3:c.1849G>...   \n",
      "\n",
      "   civic_variant_evidence_score  allele_registry_id  \\\n",
      "0                          83.0            CA124183   \n",
      "1                         100.5            CA123194   \n",
      "2                         510.0                 NaN   \n",
      "3                         510.0                 NaN   \n",
      "4                          83.0            CA124183   \n",
      "\n",
      "                                 clinvar_ids  \n",
      "0                                      14662  \n",
      "1                                      13543  \n",
      "2  375882,375883,375884,375879,375880,375881  \n",
      "3  375882,375883,375884,375879,375880,375881  \n",
      "4                                      14662  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "Output value is: \n",
      "0    3\n",
      "1    3\n",
      "2    3\n",
      "3    3\n",
      "4    3\n",
      "Name: evidence_type_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Define as entradas e saidas do DataSet\n",
    "\n",
    "input = civic.iloc[:, 1:-2]         \n",
    "print('Input values are: ') \n",
    "print(input.head())   \n",
    "output = y.loc[:, 'evidence_type_num']         \n",
    "print('Output value is: ') \n",
    "print(output.head()) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input format:  torch.Size([3897, 28]) torch.float32\n",
      "Output format:  torch.Size([3897]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "#Convertendo entradas e saidas em tensores e criando o DatasetTensor\n",
    "\n",
    "input = torch.Tensor(X.to_numpy())      \n",
    "print('\\nInput format: ', input.shape, input.dtype)      \n",
    "output = torch.tensor(output.to_numpy())         \n",
    "print('Output format: ', output.shape, output.dtype)   \n",
    "data = TensorDataset(input, output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir para treinar, validar e testar conjuntos usando random_split\n",
    "\n",
    "train_batch_size = 10        \n",
    "number_rows = len(input)    \n",
    "test_split = int(number_rows*0.3)  \n",
    "validate_split = int(number_rows*0.2) \n",
    "train_split = number_rows - test_split - validate_split     \n",
    "train_set, validate_set, test_set = random_split( \n",
    "    data, [train_split, validate_split, test_split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Dataloader para ler dados em tamanhos de lote e colocá-los na memória\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = train_batch_size, shuffle = True) \n",
    "validate_loader = DataLoader(validate_set, batch_size = 1) \n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define parâmetros do modelo\n",
    "\n",
    "input_size = list(input.shape)[1]    \n",
    "learning_rate = 0.01 \n",
    "output_size = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo a rede neural\n",
    "\n",
    "class Network(nn.Module): \n",
    "   def __init__(self, input_size, output_size): \n",
    "       super(Network, self).__init__() \n",
    "        \n",
    "       self.layer1 = nn.Linear(input_size, 24) \n",
    "       self.layer2 = nn.Linear(24, 24) \n",
    "       self.layer3 = nn.Linear(24, output_size) \n",
    "\n",
    "\n",
    "   def forward(self, x): \n",
    "       x1 = F.relu(self.layer1(x)) \n",
    "       x2 = F.relu(self.layer2(x1)) \n",
    "       x3 = self.layer3(x2) \n",
    "       return x3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar o modelo\n",
    "\n",
    "model = Network(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layer1): Linear(in_features=28, out_features=24, bias=True)\n",
       "  (layer2): Linear(in_features=24, out_features=24, bias=True)\n",
       "  (layer3): Linear(in_features=24, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define o dispositivo de execução\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(\"The model will be running on\", device, \"device\\n\") \n",
    "\n",
    "#Converte parâmetros do modelo e buffers para CPU ou Cuda\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para salvar o modelo\n",
    "\n",
    "def saveModel(): \n",
    "    path = \"./Resultado-do-Civic-Modelo.pth\" \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a função de perda com perda de entropia cruzada de classificação e um otimizador com Adam optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de treinamento\n",
    "\n",
    "def train(num_epochs): \n",
    "    best_accuracy = 0.0 \n",
    "     \n",
    "    print(\"Begin training...\") \n",
    "    for epoch in range(1, num_epochs+1): \n",
    "        running_train_loss = 0.0 \n",
    "        running_accuracy = 0.0 \n",
    "        running_vall_loss = 0.0 \n",
    "        total = 0 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop de treinamento\n",
    "\n",
    "for data in train_loader: \n",
    "        \n",
    "            inputs, outputs = data   \n",
    "            optimizer.zero_grad()            \n",
    "            predicted_outputs = model(inputs)   \n",
    "            train_loss = loss_fn(predicted_outputs, outputs)   \n",
    "            train_loss.backward()    \n",
    "            optimizer.step()\n",
    "            running_train_loss = 0.0 \n",
    "            running_train_loss +=train_loss.item()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular o valor da perda de treinamento\n",
    "\n",
    "train_loss_value = running_train_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validação do loop\n",
    "\n",
    "with torch.no_grad(): \n",
    "    model.eval() \n",
    "    for data in validate_loader: \n",
    "        inputs, outputs = data \n",
    "        predicted_outputs = model(inputs) \n",
    "        val_loss = loss_fn(predicted_outputs, outputs)\n",
    "\n",
    "#Previsão com o maior rotulo\n",
    "\n",
    "_, predicted = torch.max(predicted_outputs, 1)\n",
    "running_vall_loss = 0.0 \n",
    "running_vall_loss += val_loss.item()\n",
    "total = 0\n",
    "total += outputs.size(0)\n",
    "running_accuracy = 0.0\n",
    "running_accuracy += (predicted == outputs).sum().item() \n",
    "\n",
    "#Validação do valor de perdaa\n",
    "\n",
    "val_loss_value = running_vall_loss/len(validate_loader) \n",
    "\n",
    "#Calculo da acuracia com o numero correto de previsões\n",
    "\n",
    "accuracy = (100 * running_accuracy / total)\n",
    "\n",
    "#Salva o modelo caso a acuracia seja a melhor\n",
    "\n",
    "best_accuracy = 0.0\n",
    "if accuracy > best_accuracy: \n",
    "    saveModel() \n",
    "    best_accuracy = accuracy\n",
    "    \n",
    "#Mostra as estatísticas da época\n",
    "\n",
    "#print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model based on the test set of 1169 inputs is: 76 %\n"
     ]
    }
   ],
   "source": [
    "#Função para testar o modelo\n",
    "\n",
    "def test():\n",
    "    #Carrega o modelo que salvamos no final do loop de treinamento\n",
    "    model = Network(input_size, output_size) \n",
    "    path = \"NetModel.pth\" \n",
    "    model.load_state_dict(torch.load(path)) \n",
    "     \n",
    "    running_accuracy = 0 \n",
    "    total = 0 \n",
    "    \n",
    "with torch.no_grad(): \n",
    "    for data in test_loader: \n",
    "        inputs, outputs = data \n",
    "        outputs = outputs.to(torch.float32) \n",
    "        predicted_outputs = model(inputs) \n",
    "        _, predicted = torch.max(predicted_outputs, 1) \n",
    "        total += outputs.size(0) \n",
    "        running_accuracy += (predicted == outputs).sum().item()\n",
    "        \n",
    "print('Accuracy of the model based on the test set of', test_split ,'inputs is: %d %%' % (100 * running_accuracy / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
